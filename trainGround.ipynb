{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A training ground for sparse-coded autoencoders:\n",
    "\n",
    "**I am inheriting thise materials from an archived private repo.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import  DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn.functional as F\n",
    "#\n",
    "from cv2 import imwrite\n",
    "import os\n",
    "#\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import dataTools as D\n",
    "\n",
    "%precision 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'CelebA'\n",
    "############################\n",
    "if database_name == 'CelebA':\n",
    "    batch_size = 100\n",
    "    root = 'path/to/data/CelebA/128_crop/'\n",
    "    im_size = (128,128,3)\n",
    "elif database == 'CYale':\n",
    "    root = 'path/to/data/CYale'\n",
    "    im_size = (168, 192,1)\n",
    "#######################################\n",
    "num_channel = im_size[2]\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  \n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = D.dataRead(root,im_size,transform=fwd_transform)\n",
    "[dataset_train,dataset_test] = torch.utils.data.random_split(dataset,[int(len(dataset)* 0.8),1+int(len(dataset)* 0.2)])\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size,\n",
    "                        shuffle=False, num_workers=1)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size,\n",
    "                        shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################## Initializing the model ##############################\n",
    "num_blocks = 6\n",
    "num_filts = [40, 40, 40, 40, 40, 10]\n",
    "scale_factor = [1, 2, 1, 2, 1, 2]\n",
    "num_codes = 20\n",
    "neck_dim = 512\n",
    "k = 256\n",
    "############\n",
    "from models import Autoencoder\n",
    "net = Autoencoder((im_size[2], im_size[0], im_size[1]), num_blocks, num_filts, scale_factor, num_codes, neck_dim, k).to(device)\n",
    "net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(x_rec,x):\n",
    "    loss_BCE = nn.BCELoss()\n",
    "    #loss_MSE = nn.MSELoss()\n",
    "    #return loss_L1_Charbonnier\n",
    "    return loss_BCE(x_rec,x)\n",
    "#############################################    \n",
    "Loss_list_train = []\n",
    "Loss_list_test = []\n",
    "#############################################\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0099,weight_decay=0)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, 'min', verbose=True, factor=0.99, min_lr=0.000001,patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################## Training a new model? ##############################\n",
    "num_epoch = 200\n",
    "for i_epoch in range(num_epoch):\n",
    "    loss_train = 0.0\n",
    "    print('---------------- epoch = ', i_epoch + 1, '/',num_epoch, ' ----------')\n",
    "    for i_batch, inputs_train in enumerate(dataloader_train):\n",
    "        # print('batch = ',i_batch,end='  ')\n",
    "\n",
    "        inputs_train = inputs_train['image'].to(device) \n",
    "        outputs_train,code_train = net(inputs_train)\n",
    "        outputs_train.sigmoid_()\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(outputs_train,inputs_train)\n",
    "        loss.backward()  \n",
    "        optimizer.step()\n",
    "        scheduler.step(loss)\n",
    "        \n",
    "        loss_train += loss.item()\n",
    "        if i_epoch < 2:\n",
    "             print('loss = ', loss.item(), end='  ') \n",
    "    print('Avg train loss = ',loss_train/len(dataloader_train))\n",
    "    Loss_list_train.append(loss_train/len(dataloader_train))\n",
    "    with torch.no_grad():\n",
    "        loss_test = 0.0\n",
    "        for _, inputs_test in enumerate(dataloader_test):\n",
    "            #name_test = inputs_test['name']\n",
    "            inputs_test = inputs_test['image'].to(device) \n",
    "            outputs_test,code_test = net(inputs_test)\n",
    "            outputs_test.sigmoid_()\n",
    "            \n",
    "            loss_test += loss_function(outputs_test,inputs_test).item()\n",
    "        print('Avg test  loss = ',loss_test/len(dataloader_test))  \n",
    "        Loss_list_test.append(loss_test/len(dataloader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Loss_list_train)\n",
    "plt.plot(Loss_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## To run the network (again) on the test set?\n",
    "# ### To-Do: No need to iterate on the entire set. Just take a mini-batch.\n",
    "# with torch.no_grad():\n",
    "#     for _, inputs_test in enumerate(dataloader_test):\n",
    "#         inputs_test = inputs_test['image'].to(device) \n",
    "#         outputs_test,code_test = net(inputs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################## Saving the model? ##############################\n",
    "def list2str(L):\n",
    "    s = ''\n",
    "    for i,l in enumerate(L):\n",
    "        s += str(l)\n",
    "        if i < len(L) - 1:\n",
    "            s += '-'\n",
    "    return s\n",
    "#########################\n",
    "model_name = database_name + \\\n",
    "            '_filts' + list2str(num_filts)+ \\\n",
    "            '_scale' + list2str(scale_factor) +\\\n",
    "            '_codes' + str(num_codes) +\\\n",
    "            '_dim' + str(neck_dim) +\\\n",
    "            '_k' + str(k) + \\\n",
    "            '.pth'\n",
    "\n",
    "print(model_name)\n",
    "date = '2019-10-14'\n",
    "#os.mkdir(os.path.join('./state_dict/', date))\n",
    "##########################\n",
    "torch.save(net.state_dict(),os.path.join('./state_dict/', date, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Saving the names of test images, for future run:\n",
    "names_test = []\n",
    "for _, inputs_test in enumerate(dataloader_test): \n",
    "    names_test.extend(inputs_test['name'])\n",
    "##############################################\n",
    "f = open(os.path.join('./state_dict/', date, 'test_set_' + model_name[:-4] + '.txt'),\"x\")\n",
    "f.write(\"\\n\".join(names_test))\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    plt.plot(inputs_train[0,:].view(-1,1).cpu().numpy()[0:7000])\n",
    "    plt.plot(outputs_train[0,:].view(-1,1).cpu().numpy()[0:7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(inputs_test[10,:].view(-1,1).cpu().numpy()[0:1000])\n",
    "plt.plot(outputs_test[10,:].view(-1,1).cpu().numpy()[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(inputs_test[0,:,:,:].squeeze(0).transpose(0,2).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    plt.imshow(outputs_test[0,:,:,:].squeeze(0).transpose(0,2).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    code_tilde = torch.clone(code_test)\n",
    "    i_s = 0\n",
    "    i_e = 19\n",
    "    i_item = 19\n",
    "    # code_tilde =  2 * torch.ceil(code_tilde/2)\n",
    "    code_tilde[0:12,i_s:i_e,:] += code_tilde[i_item:i_item + 1,i_s:i_e,:]# + code_tilde[18:19 ,i_s:i_e,:]\n",
    "    #code_tilde[0:12,i_s:i_e,:] = 0\n",
    "    out_tilde = net.decoder(code_tilde).sigmoid_()\n",
    "    plt.imshow(out_tilde[0,:,:,:].squeeze(0).transpose(0,2).cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(code_test.shape)\n",
    "#plt.plot(code_test[1,0,:].cpu().numpy())\n",
    "plt.plot(code_test[10,0,:].cpu().numpy())\n",
    "plt.plot(code_tilde[10,0,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.nonzero(code_test).shape)\n",
    "print(torch.nonzero(code_tilde).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(outputs_test[0,:,:,:].view(-1,1).cpu().numpy()[7000:8000])\n",
    "plt.plot(out_tilde[0,:,:,:].view(-1,1).cpu().numpy()[7000:8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Ssaving some samples:\n",
    "utils.save_image(inputs_test[0:12,:,:,:],'samples/inputs.png',nrow=6)\n",
    "utils.save_image(outputs_test[0:12,:,:,:],'samples/outputs.png',nrow=6)\n",
    "utils.save_image(out_tilde[0:12,:,:,:],'samples/tildes.png',nrow=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(inputs_test - outputs_test).pow(2)/torch.norm(inputs_test).pow(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cv_env]",
   "language": "python",
   "name": "conda-env-pytorch_cv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
