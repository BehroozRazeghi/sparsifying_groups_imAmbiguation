{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Ground:\n",
    "\n",
    "Having trained some networks, here we are trying to play around with the codes by adding some ambiguization noise and see their decoded outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import  DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn.functional as F\n",
    "#\n",
    "from cv2 import imwrite, imread, IMWRITE_JPEG_QUALITY, COLOR_BGR2RGB\n",
    "import os\n",
    "#\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import dataTools as D\n",
    "import Tools as T\n",
    "\n",
    "from skimage.measure import compare_psnr,compare_ssim\n",
    "\n",
    "%precision 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'CelebA'\n",
    "############################\n",
    "if database_name == 'CelebA':\n",
    "    batch_size = 100\n",
    "    root = 'path/to/data/CelebA/128_crop/'\n",
    "    im_size = (128,128,3)\n",
    "elif database == 'CYale':\n",
    "    root = 'path/to/data/CYale'\n",
    "    im_size = (168, 192,1)\n",
    "#######################################\n",
    "num_channel = im_size[2]\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order not to mix test with train, here I'm reading the list of corresponding test images from a file I have saved before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  \n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names_path = './state_dict/2019-10-14/test_set_CelebA_filts40-40-40-40-40-10_scale1-2-1-2-1-2_codes20_dim512_k128.txt'\n",
    "dataset = D.dataRead_fromName(root,im_size,test_names_path, transform=fwd_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################  Loading a trained model ##############################\n",
    "num_blocks = 6\n",
    "num_filts = [40, 40, 40, 40, 40, 10]\n",
    "scale_factor = [1, 2, 1, 2, 1, 2]\n",
    "num_codes = 20\n",
    "neck_dim = 512\n",
    "k = 128\n",
    "##################################\n",
    "def list2str(L):\n",
    "    s = ''\n",
    "    for i,l in enumerate(L):\n",
    "        s += str(l)\n",
    "        if i < len(L) - 1:\n",
    "            s += '-'\n",
    "    return s\n",
    "#################################\n",
    "from models import Autoencoder\n",
    "net = Autoencoder((im_size[2], im_size[0], im_size[1]), \n",
    "                  num_blocks, num_filts, scale_factor, num_codes, neck_dim, k).to(device)\n",
    "#########################\n",
    "model_name = database_name + \\\n",
    "            '_filts' + list2str(num_filts)+ \\\n",
    "            '_scale' + list2str(scale_factor) +\\\n",
    "            '_codes' + str(num_codes) +\\\n",
    "            '_dim' + str(neck_dim) +\\\n",
    "            '_k' + str(k) + \\\n",
    "            '.pth'\n",
    "\n",
    "print(model_name)\n",
    "date = '2019-10-14'\n",
    "##########################\n",
    "net.load_state_dict(torch.load(os.path.join('./state_dict/', date, model_name)))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### To run the network  on the test set #######################\n",
    "with torch.no_grad():\n",
    "    for i, inputs in enumerate(dataloader):\n",
    "        inputs = inputs['image'].to(device) \n",
    "        outputs, code = net(inputs)\n",
    "        outputs.sigmoid_()\n",
    "        break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(inputs[0,:,:,:].squeeze(0).transpose(0,2).cpu().numpy())\n",
    "plt.figure()\n",
    "with torch.no_grad():\n",
    "    plt.imshow(outputs[0,:,:,:].squeeze(0).transpose(0,2).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Decoding with less sparsity:\n",
    "with torch.no_grad():\n",
    "    code_k64 = torch.clone(code).cpu()\n",
    "    code_k64 = T.KBest(code_k64, 64)\n",
    "    outputs_k64 = net.decoder(code_k64.to(device)).sigmoid_()\n",
    "    plt.imshow(outputs_k64[0,:,:,:].squeeze(0).transpose(0,2).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Putting some other code-maps to zero\n",
    "with torch.no_grad():\n",
    "    code_prime = torch.clone(code).cpu()\n",
    "    i_s = 0\n",
    "    i_e = 12\n",
    "    code_prime[:,i_s:i_e,:] = 0\n",
    "    outputs_prime2 = net.decoder(code_prime.to(device)).sigmoid_()\n",
    "    plt.imshow(outputs_prime2[0,:,:,:].squeeze(0).transpose(0,2).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Putting some code-maps to zero\n",
    "with torch.no_grad():\n",
    "    code_prime = torch.clone(code).cpu()\n",
    "    i_s = 8\n",
    "    i_e = 20\n",
    "    code_prime[:,::3,:] = 0\n",
    "    outputs_prime1 = net.decoder(code_prime.to(device)).sigmoid_()\n",
    "    plt.imshow(outputs_prime1[0,:,:,:].squeeze(0).transpose(0,2).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Ambiguation noise on the complement of support\n",
    "with torch.no_grad():\n",
    "    code_tilde = torch.clone(code).cpu()\n",
    "    code_tilde = T.ambiguate(code_hat, k)\n",
    "    outputs_tilde = net.decoder(code_tilde.to(device)).sigmoid_()\n",
    "    plt.imshow(outputs_tilde[0,:,:,:].squeeze(0).transpose(0,2).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## Randomly selecting k out of k':\n",
    "with torch.no_grad():\n",
    "    code_hat = torch.clone(code_tilde).cpu()\n",
    "    code_hat = T.random_guess(code_hat, k)\n",
    "    \n",
    "    outputs_hat = net.decoder(code_hat.to(device)).sigmoid_()\n",
    "    plt.imshow(outputs_hat[0,:,:,:].squeeze(0).transpose(0,2).cpu().numpy())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(code.shape)\n",
    "#plt.plot(code[1,0,:].cpu().numpy())\n",
    "plt.plot(code[10,5,0:200].cpu().numpy())\n",
    "plt.plot(code_k64[10,5,0:200].cpu().numpy())\n",
    "#plt.plot(code_tilde[10,5,0:200].cpu().numpy())\n",
    "#plt.plot(code_hat[10,5,0:200].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.nonzero(code).shape)\n",
    "print(torch.nonzero(code_tilde).shape)\n",
    "print(torch.nonzero(code_hat).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(code.view(-1).nonzero().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(code[10,1,code[10,1,:].cpu().nonzero()].reshape(-1),50)[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(outputs[0,:,:,:].view(-1,1).cpu().numpy()[7000:8000])\n",
    "plt.plot(outputs_tilde[0,:,:,:].view(-1,1).cpu().numpy()[7000:8000])\n",
    "plt.plot(outputs_hat[0,:,:,:].view(-1,1).cpu().numpy()[7000:8000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Saving some samples:\n",
    "ind_i = 30\n",
    "utils.save_image(inputs[ind_i:ind_i + 8,:,:,:],'samples/inputs.png',nrow=8)\n",
    "utils.save_image(outputs[ind_i:ind_i + 8,:,:,:],'samples/outputs.png',nrow=8)\n",
    "utils.save_image(outputs_k64[ind_i:ind_i + 8,:,:,:],'samples/outputs_k64.png',nrow=8)\n",
    "utils.save_image(outputs_tilde[ind_i:ind_i + 8,:,:,:],'samples/tildes.png',nrow=8)\n",
    "utils.save_image(outputs_hat[ind_i:ind_i + 8,:,:,:],'samples/hats.png',nrow=8)\n",
    "utils.save_image(outputs_prime1[ind_i:ind_i + 8,:,:,:],'samples/primes_1.png',nrow=8)\n",
    "utils.save_image(outputs_prime2[ind_i:ind_i + 8,:,:,:],'samples/primes_2.png',nrow=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality assessment:\n",
    "\n",
    "* PSNR\n",
    "* SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.norm(inputs - outputs).pow(2)/torch.norm(inputs).pow(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_outputs = []\n",
    "ssim_outputs = []\n",
    "\n",
    "psnr_outputs_k64 = []\n",
    "ssim_outputs_k64 = []\n",
    "\n",
    "psnr_tildes = []\n",
    "ssim_tildes = []\n",
    "\n",
    "psnr_hats = []\n",
    "ssim_hats = []\n",
    "\n",
    "for i in range(inputs.shape[0]):\n",
    "    psnr_outputs.append(\n",
    "        compare_psnr(\n",
    "        inputs[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy(),\n",
    "        outputs[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy()) )\n",
    "    \n",
    "    ssim_outputs.append(\n",
    "        compare_ssim(\n",
    "        inputs[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy(),\n",
    "        outputs[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy(), multichannel=True) )\n",
    "    \n",
    "    \n",
    "    psnr_outputs_k64.append(\n",
    "        compare_psnr(\n",
    "        inputs[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy(),\n",
    "        outputs_k64[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy()) )\n",
    "    \n",
    "    ssim_outputs_k64.append(\n",
    "        compare_ssim(\n",
    "        inputs[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy(),\n",
    "        outputs_k64[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy(), multichannel=True) )\n",
    "    \n",
    "    \n",
    "    \n",
    "    psnr_tildes.append(\n",
    "        compare_psnr(\n",
    "        inputs[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy(),\n",
    "        outputs_tilde[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy()) )\n",
    "    \n",
    "    ssim_tildes.append(\n",
    "        compare_ssim(\n",
    "        inputs[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy(),\n",
    "        outputs_tilde[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy(), multichannel=True) )\n",
    "    \n",
    "    \n",
    "    psnr_hats.append(\n",
    "        compare_psnr(\n",
    "        inputs[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy(),\n",
    "        outputs_hat[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy()) )\n",
    "    \n",
    "    ssim_hats.append(\n",
    "        compare_ssim(\n",
    "        inputs[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy(),\n",
    "        outputs_hat[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy(), multichannel=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(psnr_outputs))\n",
    "print(np.mean(ssim_outputs))\n",
    "\n",
    "print(np.mean(psnr_outputs_k64))\n",
    "print(np.mean(ssim_outputs_k64))\n",
    "\n",
    "\n",
    "print(np.mean(psnr_tildes))\n",
    "print(np.mean(ssim_tildes))\n",
    "\n",
    "print(np.mean(psnr_hats))\n",
    "print(np.mean(ssim_hats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnr_jpg = []\n",
    "ssim_jpg = []\n",
    "for i in range(inputs.shape[0]):\n",
    "    \n",
    "    img = inputs[i,:,:,:].squeeze(0).transpose(0,2).cpu().numpy() \n",
    "    imwrite('tmp.jpg', img * 256, [IMWRITE_JPEG_QUALITY, 4])\n",
    "    image = imread('tmp.jpg' , COLOR_BGR2RGB)\n",
    "    image = image.astype('float32')/256\n",
    "    psnr_jpg.append(compare_psnr(img, image))\n",
    "    ssim_jpg.append(compare_ssim(img, image, multichannel=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(psnr_jpg))\n",
    "print(np.mean(ssim_jpg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_KBytes(m, k, L):\n",
    "    H = -(k/m) * np.log2((k/m)) - (1 - (k/m)) * np.log2(1 - (k/m))\n",
    "    return H * m * L  /(8 * 1024)\n",
    "    \n",
    "def calculate_psnr(m, k, L, im_size):\n",
    "    H = -(k/m) * np.log2((k/m)) - (1 - (k/m)) * np.log2(1 - (k/m))\n",
    "    return H * m * L / np.prod(im_size)\n",
    "\n",
    "print(calculate_KBytes(512, 128, 20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cv_env]",
   "language": "python",
   "name": "conda-env-pytorch_cv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
